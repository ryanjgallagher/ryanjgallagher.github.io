{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd886a2f",
   "metadata": {},
   "source": [
    "# Practicum 8 - Nicki Minaj Vaccine Hesitancy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12575b91",
   "metadata": {},
   "source": [
    "In mid-September, rapper Nicki Minaj posted the [following tweet](https://twitter.com/nickiminaj/status/1437532566945341441): \n",
    "\n",
    "```\n",
    "My cousin in Trinidad wonâ€™t get the vaccine cuz his friend got it & became impotent. His testicles became swollen. His friend was weeks away from getting married, now the girl called off the wedding. So just pray on it & make sure youâ€™re comfortable with ur decision, not bullied\n",
    "```\n",
    "\n",
    "The vaccine hesitancy expressed by Nicki Minaj (and the way she expressed it with this story) surprised many people. It quickly became a partisan discussion when Tucker Carlson at Fox News ran a segment on her tweet expressing his support for her skepticism, and she subsequently [tweeted it](https://twitter.com/nickiminaj/status/1438248319650656256?lang=en).\n",
    "\n",
    "The outbreak of conversation started by Nicki Minaj's tweet led to a flurry of emotions. This week, we'll use a dataset of tweets discussing Nicki Minaj and her controversial tweet. In particular, we'll look at the *sentiment* of the tweets that were posted. Sentiment analysis is a way of trying to quantify how emotion is expressed in text. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db518bd",
   "metadata": {},
   "source": [
    "-----------------\n",
    "\n",
    "### Important Note!\n",
    "\n",
    "Do _**not**_ share this data outside of class! It is a violation of Twitter's Terms of Service to share full tweet data publicly.\n",
    "\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91405c05",
   "metadata": {},
   "source": [
    "## Dictionary-Based Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedd50a2",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c871ddc",
   "metadata": {},
   "source": [
    "There are many, many ways to conduct sentiment analysis. We're going to do what is called *dictionary-based sentiment analysis*. Imagine that we have a a set of words and that each word is associated with some amount of happiness. So, for example, if we said that happiness falls on a scale from 1 to 9, we would expect words like \"love\" and \"sunny\" to have high happiness scores (close to 9), while we would expect words like \"pandemic\" and \"murder\" to have low happiness scores (close to 1). \n",
    "\n",
    "To calculate the \"sentiment\" or \"happiness\" of a text, we split it into each of its individual words. We then look at each word and check if it's in our sentiment dictionary to see if we have a happiness score for it. If we do, then we'll add that sentiment to the total for the sentence. We then divide the total sentiment by the total number of words that we scored to get the average sentiment of the text. \n",
    "\n",
    "For example, say we had a sentiment dictionary with just three words and scores: \"coronavirus\" with a score of 1.1, \"vaccines\" with a score of 7.3, and \"impotence\" with a score of 2.9. And say we had the following tweet:\n",
    "\n",
    "```\n",
    "Contrary to Nicki Minaj claims, no, none of the available coronavirus vaccines have been linked to testicular swelling or impotence\n",
    "```\n",
    "\n",
    "To get the average sentiment for the tweet, we look at the words and we see that \"coronavirus\", \"vaccines\", and \"impotence\" all appear exactly once. So, we add together their sentiment scores and divide by 3 (the total number of words that we scored): \n",
    "\n",
    "```\n",
    "(1.1 + 7.3 + 2.9) / 3 = 3.76\n",
    "```\n",
    "\n",
    "On our scale from 1 to 9 (where 5 is the middle), our dictionary-based sentiment analysis would say that this tweet is relatively not happy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c95f179",
   "metadata": {},
   "source": [
    "### Be Wary of Sentiment Analysis (Especially on Short Texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e4af35",
   "metadata": {},
   "source": [
    "Sentiment analysis is an entire branch of computer science (and the field of natural language processing, more specifically) and it is very difficult to conduct accurately. In particular, dictionary-based sentiment analysis is very easy to fool if we're working with short texts like tweets. Consider the following sentence:\n",
    "\n",
    "```\n",
    "I'm not happy about my birthday party this week\n",
    "```\n",
    "\n",
    "Dictionary-based sentiment analysis looks at _each word individually_. This means that it would see three positive words (\"happy\", \"birthday\", \"party\") and just one negative word (\"not\"). A naive dictionary-based approach will rate this sentence as a positive because it does not understand that \"not\" is negating the emotions expressed in the rest of the sentence. There are many ways to try and address this issue, but they're beyond the scope of this one assignment. There is one saving grace though: the longer our texts, the less negations, sarcasm, and other pathologies affect the overall sentiment. The oddities of the language all smooth out if we have a lot of text. \n",
    "\n",
    "In the first part of the assignment I'll ask you to calculate the sentiment of individual tweets. In general, I do _**not**_ recommend doing that with dictionary-based sentiment analysis. Instead, I typically recommend calculating the sentiment of a large group of tweets, which is what we'll do in the last part of the assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c326cd14",
   "metadata": {},
   "source": [
    "## 1. Reading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b795fa11",
   "metadata": {},
   "source": [
    "### 1a. Sentiment Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb52652f",
   "metadata": {},
   "source": [
    "We want to start by reading in our sentiment dictionary. We'll be using the labMT sentiment dictionary, which you can read more about [here](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0026752). Words fall on a continuous scale from 1 to 9, where 1 is the least happy, and 9 is the most happy.\n",
    "\n",
    "Write a function to read a CSV file of word-score pairs (like `labMT-en.csv`) into a Python dictionary where keys are words and values are sentiment scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ac8af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sentiment_dict(filename):\n",
    "    \"\"\"\n",
    "    Gets sentiment scores from a CSV file of the form word,score\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename: str\n",
    "        The name of the file to read\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    word2score: dict\n",
    "        Dictionary where keys are words and values are sentiment scores\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68636ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_f = 'labMT-en.csv'\n",
    "word2score = load_sentiment_dict(sentiment_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099a4b82",
   "metadata": {},
   "source": [
    "### 1b. Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65603021",
   "metadata": {},
   "source": [
    "Next, we want to load the tweets. The tweets are in a new file format: `.json`. JSON is a way of storing data in a set of nested dictionaries. JSON files store multiple JSON objects, one on each line. \n",
    "\n",
    "I have written a function below that loads the tweets from the JSON file. Notice how it is _very_ similar to other functions we've written for reading files. The only difference is using `loads` function instead of `split`. Remember to import the `json` module too by running the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30fd2562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8244a744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tweets(filename):\n",
    "    \"\"\"\n",
    "    Gets tweet data from a JSON file\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename: str\n",
    "        The name of the file to read\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    tweets: list of dicts\n",
    "        List where each element is a dictionary with the data for one tweet\n",
    "    \"\"\"\n",
    "    tweets = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            tweet = json.loads(line.strip())\n",
    "            tweets.append(tweet)\n",
    "            \n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5129b316",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_f = 'vaccine_tweets.json'\n",
    "tweets = load_tweets(tweets_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37db988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "beff8b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '1437538884209020933',\n",
       " 'text': \"RT @crissles: @NICKIMINAJ your cousin's friend prolly just picked up an STD but please keep going ðŸ’€\",\n",
       " 'lang': 'en',\n",
       " 'author_id': '130224558',\n",
       " 'created_at': '2021-09-13T22:09:12',\n",
       " 'conversation_id': '1437538884209020933',\n",
       " 'possibly_sensitive': False,\n",
       " 'reply_settings': 'everyone',\n",
       " 'source': 'Twitter for iPhone',\n",
       " 'public_metrics': {'retweet_count': 8424,\n",
       "  'reply_count': 0,\n",
       "  'like_count': 0,\n",
       "  'quote_count': 0},\n",
       " 'referenced_tweets': [{'retweeted': '1437534026324221958'}],\n",
       " 'user': {'username': 'Vrn_TM',\n",
       "  'name': 'Vâ„¢',\n",
       "  'created_at': '2010-04-06T17:57:36',\n",
       "  'description': 'This is the Unofficial Twitter Account of VLA ðŸ‡­ðŸ‡¹',\n",
       "  'location': 'Boston, MA',\n",
       "  'pinned_tweet_id': None,\n",
       "  'public_metrics': {'followers_count': 99,\n",
       "   'following_count': 357,\n",
       "   'tweet_count': 54},\n",
       "  'url': None,\n",
       "  'profile_image_url': 'https://pbs.twimg.com/profile_images/1262542770238967810/YIzrsRpx_normal.jpg',\n",
       "  'verified': False}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e869356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785df632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82c56962",
   "metadata": {},
   "source": [
    "I encourage you to spend a moment looking at the data. Examine the nested dictionary structure and try to make sense of it. Play around with it by entering different keys if you're not sure about how the data is stored. All of the tweet fields are explained [here](https://developer.twitter.com/en/docs/twitter-api/data-dictionary/object-model/tweet), and all of the user fields are explained [here](https://developer.twitter.com/en/docs/twitter-api/data-dictionary/object-model/user)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da2a8d64",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1\n",
      "--------------------------------------\n",
      "\n",
      "{'author_id': '130224558',\n",
      " 'conversation_id': '1437538884209020933',\n",
      " 'created_at': '2021-09-13T22:09:12',\n",
      " 'id': '1437538884209020933',\n",
      " 'lang': 'en',\n",
      " 'possibly_sensitive': False,\n",
      " 'public_metrics': {'like_count': 0,\n",
      "                    'quote_count': 0,\n",
      "                    'reply_count': 0,\n",
      "                    'retweet_count': 8424},\n",
      " 'referenced_tweets': [{'retweeted': '1437534026324221958'}],\n",
      " 'reply_settings': 'everyone',\n",
      " 'source': 'Twitter for iPhone',\n",
      " 'text': \"RT @crissles: @NICKIMINAJ your cousin's friend prolly just picked up \"\n",
      "         'an STD but please keep going ðŸ’€',\n",
      " 'user': {'created_at': '2010-04-06T17:57:36',\n",
      "          'description': 'This is the Unofficial Twitter Account of VLA ðŸ‡­ðŸ‡¹',\n",
      "          'location': 'Boston, MA',\n",
      "          'name': 'Vâ„¢',\n",
      "          'pinned_tweet_id': None,\n",
      "          'profile_image_url': 'https://pbs.twimg.com/profile_images/1262542770238967810/YIzrsRpx_normal.jpg',\n",
      "          'public_metrics': {'followers_count': 99,\n",
      "                             'following_count': 357,\n",
      "                             'tweet_count': 54},\n",
      "          'url': None,\n",
      "          'username': 'Vrn_TM',\n",
      "          'verified': False}}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Example 2\n",
      "--------------------------------------\n",
      "\n",
      "{'author_id': '35573460',\n",
      " 'conversation_id': '1438251218179014656',\n",
      " 'created_at': '2021-09-15T23:06:11',\n",
      " 'id': '1438277997115547648',\n",
      " 'lang': 'en',\n",
      " 'possibly_sensitive': False,\n",
      " 'public_metrics': {'like_count': 19,\n",
      "                    'quote_count': 0,\n",
      "                    'reply_count': 1,\n",
      "                    'retweet_count': 1},\n",
      " 'referenced_tweets': [{'replied_to': '1438251218179014656'}],\n",
      " 'reply_settings': 'everyone',\n",
      " 'source': 'Twitter for iPhone',\n",
      " 'text': '@NICKIMINAJ I had covid, got an antibody test. The test registers '\n",
      "         'antibody levels between 1 to 15. My test said my levels are 20. My '\n",
      "         'antibody levels are very high. I have natural immunity. Why do I '\n",
      "         'still have to still get the vaccine to  go to a '\n",
      "         'stadium/restaurant/etc..?',\n",
      " 'user': {'created_at': '2009-04-26T21:41:05',\n",
      "          'description': 'Poker Player, World Traveler, Room Service '\n",
      "                         'Connoisseur',\n",
      "          'location': 'Las Vegas, Nevada',\n",
      "          'name': 'PokerPlayinFool',\n",
      "          'pinned_tweet_id': None,\n",
      "          'profile_image_url': 'https://pbs.twimg.com/profile_images/682269910370762752/7Q0vCkrW_normal.jpg',\n",
      "          'public_metrics': {'followers_count': 50,\n",
      "                             'following_count': 451,\n",
      "                             'tweet_count': 325},\n",
      "          'url': None,\n",
      "          'username': 'PokerPlayinFool',\n",
      "          'verified': False}}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Example 3\n",
      "--------------------------------------\n",
      "\n",
      "{'author_id': '2999464870',\n",
      " 'conversation_id': '1438284808694685698',\n",
      " 'created_at': '2021-09-15T23:33:15',\n",
      " 'hashtags': ['freenicki', 'unfair'],\n",
      " 'id': '1438284808694685698',\n",
      " 'lang': 'en',\n",
      " 'possibly_sensitive': False,\n",
      " 'public_metrics': {'like_count': 45,\n",
      "                    'quote_count': 0,\n",
      "                    'reply_count': 3,\n",
      "                    'retweet_count': 9},\n",
      " 'reply_settings': 'everyone',\n",
      " 'source': 'Twitter for iPhone',\n",
      " 'text': 'Skai Jackson Was Right Wtf this is embarrassing #freenicki #unfair '\n",
      "         'https://t.co/y993BW3fYH',\n",
      " 'urls': [{'display_url': 'pic.twitter.com/y993BW3fYH',\n",
      "           'end': 90,\n",
      "           'expanded_url': 'https://twitter.com/IamMoone94/status/1438284808694685698/photo/1',\n",
      "           'start': 67,\n",
      "           'url': 'https://t.co/y993BW3fYH'}],\n",
      " 'user': {'created_at': '2015-01-26T10:44:21',\n",
      "          'description': 'love ya happiness https://t.co/R2eAU4QjkN',\n",
      "          'location': 'MALMO BITCHES! ',\n",
      "          'name': 'Maxmud ðŸŽ‡',\n",
      "          'pinned_tweet_id': '879420645901312001',\n",
      "          'profile_image_url': 'https://pbs.twimg.com/profile_images/1434203904275881987/hyvIXqXl_normal.jpg',\n",
      "          'public_metrics': {'followers_count': 1077,\n",
      "                             'following_count': 2947,\n",
      "                             'tweet_count': 27304},\n",
      "          'url': 'http://www.instagram.com/maxmudhaji',\n",
      "          'username': 'IamMoone94',\n",
      "          'verified': False}}\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# \"pprint\" stands for \"pretty print.\" It's good for visualizing nested dictionary structures\"\n",
    "from pprint import pprint\n",
    "\n",
    "n_examples = 3\n",
    "for indx in range(n_examples):\n",
    "    print(f'Example {indx+1}')\n",
    "    print('--------------------------------------\\n')\n",
    "    pprint(tweets[indx])\n",
    "    print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9f3b3e",
   "metadata": {},
   "source": [
    "## 2. Cleaning Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821628a2",
   "metadata": {},
   "source": [
    "Before we can conduct our sentiment analysis, we need to clean our text. Write a function that takes a piece of text and does the following:\n",
    "\n",
    "1. Splits the text into individual words\n",
    "2. Lower cases each word\n",
    "3. Removes any hashtags (words that start with a # symbol, like #freenickiminaj or #vaccines)\n",
    "4. Removes any handles and mentions (words that start with a @ symbol, like @NICKIMINAJ or @StephenAtHome)\n",
    "5. Removes any punctuation\n",
    "\n",
    "The final output should be a _list of words_. Hints:\n",
    "- Remember, you have the `split` function in your toolkit\n",
    "- Python has a built-in list of punctuation that you can get by adding the following to your code:\n",
    "\n",
    "```python\n",
    "# Note: this can be outside of the function definition (and I recommend it)\n",
    "import string\n",
    "punctuation = set(string.punctuation)\n",
    "```\n",
    "\n",
    "- You can combine a list of characters into a string like so:\n",
    "\n",
    "```python\n",
    "chars = ['r', 'y', 'a', 'n', ' ', 'g' , 'a', 'l', 'l', 'a', 'g', 'h', 'e', 'r']\n",
    "name = ''.join(chars)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c3dc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Preprocesses text for sentiment analysis by lowering the case, \n",
    "    removing hashtags and handles, and removing any punctuation\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text: str\n",
    "        The text to clean\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    cleaned_text: list of strs\n",
    "        List of strings where each element is a word from the cleaned text\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e600728",
   "metadata": {},
   "source": [
    "## 3. Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d234ec",
   "metadata": {},
   "source": [
    "### 3a. Sentiment of an Individual Tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2133e5",
   "metadata": {},
   "source": [
    "Write a function that takes a tweet dictionary object (not just text) and gets the average sentiment of the tweet. \n",
    "\n",
    "1. Get the text of the tweet\n",
    "2. Clean the tweet text\n",
    "3. Use the sentiment dictionary to sum the total sentiment of the tweet\n",
    "4. Divide by the total by the number of words scored to get the average sentiment\n",
    "5. If the total number of words scores is 0 (i.e. we can't measure sentiment for the tweet with our dictionary because no words in the tweet are in our dictionary), return `None`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ea3159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweet_sentiment(tweet, word2score):\n",
    "    \"\"\"\n",
    "    Calculates the average sentiment for an individual tweet \n",
    "    using a sentiment dictionary\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tweet: dict\n",
    "        Dictionary representing the data for a tweet\n",
    "    word2score: dict\n",
    "        Dictionary where keys are words and values are sentiment scores\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    avg_sentiment: float\n",
    "        The average sentiment of the tweet\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496bc839",
   "metadata": {},
   "source": [
    "### 3b. Auditing Sentiment of Individual Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695374e4",
   "metadata": {},
   "source": [
    "Now, write code to get the 5 tweets with the highest sentiment, and the 5 tweets with the lowest sentiment. Your code does not have to be wrapped in a function, but it should print out three things:\n",
    "1. The tweet ID\n",
    "2. The _original_ tweet text (not the cleaned text)\n",
    "3. The sentiment score\n",
    "\n",
    "Do these match your intuition of what should be lowest and highest? Why are these the tweets with the highest and lowest sentiment scores?\n",
    "\n",
    "**Note, content warning:** If your code is working properly, one of the lowest sentiment tweets will have a gendered slur in it.\n",
    "\n",
    "\n",
    "**Hint:** Look at how we used `sorted` a few weeks ago with our baseball leaderboards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc50401b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7096c666",
   "metadata": {},
   "source": [
    "### 3c. Sentiment of a Group of Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177d2ac9",
   "metadata": {},
   "source": [
    "Write a function that takes a list of tweets and calculates the average sentiment across _all_ of them together. That is treat all of the tweets like one, single large text and calculate a single sentiment score across all of them. Remember, the average sentiment is the total sentiment divided by the total number of words that were scored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff4b4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus_sentiment(tweets, word2score):\n",
    "    \"\"\"\n",
    "    Calculates the average sentiment of a corpus of tweets\n",
    "    using a sentiment dictionary\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tweest: list of dicts\n",
    "         List where each element is a dictionary with the data for one tweet\n",
    "    word2score: dict\n",
    "        Dictionary where keys are words and values are sentiment scores\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    avg_sentiment: float\n",
    "        The average sentiment of the entire corpus of tweets\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f935bca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_sentiment = get_corpus_sentiment(tweets, word2score)\n",
    "print(avg_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1859518a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f20c7d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'hi my name is ryan #old'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "555304a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = text.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41a59fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi', 'my', 'name', 'is', 'ryan', '#old']\n"
     ]
    }
   ],
   "source": [
    "print(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0db05901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "my\n",
      "name\n",
      "is\n",
      "ryan\n",
      "#old\n"
     ]
    }
   ],
   "source": [
    "for string in strings:\n",
    "    print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a0447a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "if 'a' in 'animal':\n",
    "    print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b69606a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for n in [1, 2, 3, 4, 5, 6]:\n",
    "    if n % 2 == 0:\n",
    "        continue\n",
    "        \n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d90f51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7e8740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1659754f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Hi my name is Ryan #gradschool'\n",
    "split_words = text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f7ed736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi', 'my', 'name', 'is', 'ryan', '#gradschool']\n"
     ]
    }
   ],
   "source": [
    "print(split_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390cfa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
